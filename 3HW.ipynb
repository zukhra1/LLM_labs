{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 33551,
          "sourceType": "modelInstanceVersion",
          "modelInstanceId": 28083
        }
      ],
      "dockerImageVersionId": 30732,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Task 1**"
      ],
      "metadata": {
        "id": "iNVlPQ2N4flK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers datasets kaggle huggingface_hub\n",
        "\n",
        "from huggingface_hub import login\n",
        "\n",
        "login(token=\"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\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q0X4a22hv4j_",
        "outputId": "bbcc0bed-3fac-4913-8a67-3a99d2ea0718"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.2)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.20.0)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.6.14)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.23.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.15.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (16.1.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]<=2024.5.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.6.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.0.7)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.12.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
            "Token is valid (permission: fineGrained).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "model_name = \"gpt2\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8wx327fxPdo",
        "outputId": "e4f3cbaa-91c5-4357-d6be-047578ae55cb"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Once upon a time, the world was a place of great beauty and great danger. The world was\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generation_params = [\n",
        "    {\n",
        "        \"prompt\": \"Once upon a time in a galaxy far, far away,\",\n",
        "        \"max_length\": 100,\n",
        "        \"num_return_sequences\": 3,\n",
        "        \"temperature\": 0.7,\n",
        "        \"top_p\": 0.9,\n",
        "        \"top_k\": 50,\n",
        "        \"do_sample\": True,\n",
        "    },\n",
        "    {\n",
        "        \"prompt\": \"In a futuristic city where technology reigns supreme,\",\n",
        "        \"max_length\": 120,\n",
        "        \"num_return_sequences\": 2,\n",
        "        \"temperature\": 0.8,\n",
        "        \"top_p\": 0.9,\n",
        "        \"top_k\": 50,\n",
        "        \"do_sample\": True,\n",
        "    },\n",
        "    {\n",
        "        \"prompt\": \"In the enchanted forest, the ancient trees whispered secrets to\",\n",
        "        \"max_length\": 80,\n",
        "        \"num_return_sequences\": 1,\n",
        "        \"temperature\": 0.6,\n",
        "        \"top_p\": 0.9,\n",
        "        \"top_k\": 50,\n",
        "        \"do_sample\": True,\n",
        "    },\n",
        "]\n",
        "\n",
        "for params in generation_params:\n",
        "    print(f\"Prompt: {params['prompt']}\")\n",
        "    inputs = tokenizer(params[\"prompt\"], return_tensors=\"pt\")\n",
        "    outputs = model.generate(\n",
        "        inputs[\"input_ids\"],\n",
        "        max_length=params[\"max_length\"],\n",
        "        num_return_sequences=params[\"num_return_sequences\"],\n",
        "        temperature=params[\"temperature\"],\n",
        "        top_p=params[\"top_p\"],\n",
        "        top_k=params[\"top_k\"],\n",
        "        do_sample=params[\"do_sample\"]\n",
        "    )\n",
        "\n",
        "    for i, output in enumerate(outputs):\n",
        "        generated_text = tokenizer.decode(output, skip_special_tokens=True)\n",
        "        print(f\"Generated text {i + 1}: {generated_text}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9hxTDfVoyOol",
        "outputId": "9504092f-b0e1-407b-83fd-8a95e5fbb3ff"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: Once upon a time in a galaxy far, far away,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated text 1: Once upon a time in a galaxy far, far away, you must find a way to escape the clutches of the mysterious forces of darkness.\n",
            "\n",
            "The game features a number of new characters, including the famous and legendary characters from the original Star Wars. These characters are all based on the character and their roles in the story. The most important characters are:\n",
            "\n",
            "The Emperor - the Emperor of the Empire\n",
            "\n",
            "- the Emperor of the Empire The Shadow - the Shadow of the Empire\n",
            "\n",
            "\n",
            "Generated text 2: Once upon a time in a galaxy far, far away, the most important thing is to protect your own people.\n",
            "\n",
            "You are the only one who can do so.\n",
            "\n",
            "In order to do so, you must protect your people, your home, your family, your loved ones, and your nation.\n",
            "\n",
            "In this new universe, we have arrived. You are the first ones who have come to protect our nation. You are the first ones to protect the planet from the horrors of\n",
            "\n",
            "Generated text 3: Once upon a time in a galaxy far, far away, you see a small alien planet, called a \"bazaar\" in the asteroid belt. In the bazaar, you can buy supplies, repair weapons, and build a city. The city is made up of a variety of goods and services. The goods that you buy are used to make a living. The services that you provide are usually quite useful, but not always so. The bazaar is a place where you can buy weapons and\n",
            "\n",
            "Prompt: In a futuristic city where technology reigns supreme,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated text 1: In a futuristic city where technology reigns supreme, it's almost always in the hands of a person who can't help but question his ability to do what he does best:\n",
            "\n",
            "\"I don't know how you would feel if you took a car, but you could drive for hours without stopping,\" he said. \"You'd be a little bit less physically active, but you'd be able to keep going.\"\n",
            "\n",
            "A lot of the new cars on the road today aren't designed to be driving. The biggest change is that they're more like a real estate agent than a car.\n",
            "\n",
            "Generated text 2: In a futuristic city where technology reigns supreme, the future of life is at stake, and the world has been put in the position of having to navigate a maze of dangerous obstacles.\n",
            "\n",
            "From the start, this game was the most ambitious in the series, and the game's art style was impressive. In many ways, it's the art style of the future, which is the kind that makes the world feel real.\n",
            "\n",
            "This is an interesting point because while the world of the game is more or less like a dream, it doesn't really resemble anything else. A lot of what\n",
            "\n",
            "Prompt: In the enchanted forest, the ancient trees whispered secrets to\n",
            "Generated text 1: In the enchanted forest, the ancient trees whispered secrets to the young man.\n",
            "\n",
            "\"You can see the runes in the trees, and they are the same. You can see them in the sky, and they are the same. You can see the runes in the sky, and they are the same.\"\n",
            "\n",
            "The old man looked at the young man.\n",
            "\n",
            "\"You can see the\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Strengths of the baseline's model:\n",
        "* Generates creative and imaginative content. Stories can follow a narrative structure.\n",
        "* Thematic consistency.\n",
        "* The modeel generally priduces gramatically correct text.\n",
        "* Use of descriptive language.\n",
        "\n",
        "\n",
        "\n",
        "Weaknesses:\n",
        "* Sometimes lacks depth in character development or plot complexity.\n",
        "* Responses can occasionally stray from the initial theme or introduce inconsisetncies in the narrative flow.\n",
        "* Struggles  with maintaining context over longer texts.\n",
        "\n",
        "The GPT-2 Model performs well in generating coherent and fluent text, especially in imaginative and speculative scenarios.\n"
      ],
      "metadata": {
        "id": "4676PzofiVVz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 2"
      ],
      "metadata": {
        "id": "EHKuKNuviVV0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from datasets import load_dataset\n",
        "\n",
        "# Load the dataset\n",
        "dataset = load_dataset('Anthropic/hh-rlhf')\n"
      ],
      "metadata": {
        "id": "b4KWntBq4ecQ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NVwjJY9j7OXP",
        "outputId": "e03cd5a2-4d58-4dd7-e66b-be43834f58ed"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['chosen', 'rejected'],\n",
            "        num_rows: 160800\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['chosen', 'rejected'],\n",
            "        num_rows: 8552\n",
            "    })\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def process_dataset(dataset, split_name):\n",
        "    data = []\n",
        "    for example in dataset[split_name]:\n",
        "        chosen_response = example['chosen'].strip()\n",
        "        rejected_response = example['rejected'].strip()\n",
        "\n",
        "        last_colon_pos_chosen = chosen_response.rfind(':')\n",
        "        last_colon_pos_rejected = rejected_response.rfind(':')\n",
        "\n",
        "        prompt_chosen = chosen_response[:last_colon_pos_chosen + 1].strip()\n",
        "        prompt_rejected = rejected_response[:last_colon_pos_rejected + 1].strip()\n",
        "\n",
        "        if len(prompt_chosen) >= len(prompt_rejected):\n",
        "            prompt = prompt_chosen\n",
        "        else:\n",
        "            prompt = prompt_rejected\n",
        "\n",
        "        chosen_response = chosen_response[last_colon_pos_chosen + 1:].strip()\n",
        "        rejected_response = rejected_response[last_colon_pos_rejected + 1:].strip()\n",
        "\n",
        "        data.append({'prompt': prompt, 'response': chosen_response, 'reward': 1})\n",
        "        data.append({'prompt': prompt, 'response': rejected_response, 'reward': 0})\n",
        "\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "train_data = process_dataset(dataset, 'train')\n",
        "\n",
        "print(train_data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S4XpkSaj80cf",
        "outputId": "bbc0da49-3764-4d13-ad79-9cb7007c6919"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                              prompt  \\\n",
            "0  Human: What are some cuss words in english?\\n\\...   \n",
            "1  Human: What are some cuss words in english?\\n\\...   \n",
            "2  Human: What kind of noises did dinosaurs make?...   \n",
            "3  Human: What kind of noises did dinosaurs make?...   \n",
            "4  Human: If you were going to steal from a conve...   \n",
            "\n",
            "                                            response  reward  \n",
            "0                   I haven't even thought about it.       1  \n",
            "1                                               Ass.       0  \n",
            "2                                      You can read?       1  \n",
            "3           there’s a lot of stuff humans don’t know       0  \n",
            "4  I really couldn’t say, I’m not familiar with s...       1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = process_dataset(dataset, \"test\")\n",
        "\n",
        "print(test_data.head())"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-30T18:34:06.739336Z",
          "iopub.execute_input": "2024-06-30T18:34:06.740412Z",
          "iopub.status.idle": "2024-06-30T18:34:07.126417Z",
          "shell.execute_reply.started": "2024-06-30T18:34:06.740364Z",
          "shell.execute_reply": "2024-06-30T18:34:07.125497Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PbBuJ0pDiVV1",
        "outputId": "c15a10f3-b317-4f75-80d6-edb8e7cc304f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                              prompt  \\\n",
            "0  Human: what are some pranks with a pen i can d...   \n",
            "1  Human: what are some pranks with a pen i can d...   \n",
            "2  Human: How much alcohol can I drink per day?\\n...   \n",
            "3  Human: How much alcohol can I drink per day?\\n...   \n",
            "4  Human: what are some pranks i can play on a ne...   \n",
            "\n",
            "                                            response  reward  \n",
            "0  No, sorry!  All of these involve a pen, the po...       1  \n",
            "1  use the pen as a zipper.  It’s where you write...       0  \n",
            "2  Sounds like alcohol is something you use to ca...       1  \n",
            "3  I’m glad that you’re enjoying your alcohol int...       0  \n",
            "4  I’d recommend you pick a person who seems gull...       1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import DistilBertTokenizer, DistilBertModel, AdamW\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "class RewardModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(RewardModel, self).__init__()\n",
        "        self.bert = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.fc = nn.Linear(self.bert.config.hidden_size, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        pooled_output = outputs.last_hidden_state[:, 0, :]\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.fc(pooled_output)\n",
        "        probs = self.sigmoid(logits)\n",
        "        return probs\n",
        "\n",
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "model = RewardModel()\n",
        "\n",
        "prompt = \"What is your favorite book?\"\n",
        "response = \"My favorite book is 'To Kill a Mockingbird'.\"\n",
        "concatenated_text = f\"{prompt} {response}\"\n",
        "\n",
        "inputs = tokenizer.encode_plus(\n",
        "    concatenated_text,\n",
        "    add_special_tokens=True,\n",
        "    max_length=512,\n",
        "    truncation=True,\n",
        "    padding='max_length',\n",
        "    return_tensors='pt'\n",
        ")\n",
        "\n",
        "input_ids = inputs['input_ids']\n",
        "attention_mask = inputs['attention_mask']\n",
        "\n",
        "output_probs = model(input_ids, attention_mask)\n",
        "print(\"Output probabilities:\", output_probs.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ne9nmy1m955O",
        "outputId": "ccbc253f-6465-44be-90a8-27d93475b872"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output probabilities: 0.5599325299263\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "cfAqKUzWDpC1",
        "outputId": "66ddf960-5d22-4e62-e0af-470b0814530d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   prompt  \\\n",
              "0       Human: What are some cuss words in english?\\n\\...   \n",
              "1       Human: What are some cuss words in english?\\n\\...   \n",
              "2       Human: What kind of noises did dinosaurs make?...   \n",
              "3       Human: What kind of noises did dinosaurs make?...   \n",
              "4       Human: If you were going to steal from a conve...   \n",
              "...                                                   ...   \n",
              "321595  Human: What is the proper way to thaw a turkey...   \n",
              "321596  Human: What does an ultrasound technician do?\\...   \n",
              "321597  Human: What does an ultrasound technician do?\\...   \n",
              "321598  Human: Are there any risks or dangers to using...   \n",
              "321599  Human: Are there any risks or dangers to using...   \n",
              "\n",
              "                                                 response  reward  \n",
              "0                        I haven't even thought about it.       1  \n",
              "1                                                    Ass.       0  \n",
              "2                                           You can read?       1  \n",
              "3                there’s a lot of stuff humans don’t know       0  \n",
              "4       I really couldn’t say, I’m not familiar with s...       1  \n",
              "...                                                   ...     ...  \n",
              "321595  Interesting question! Thawing a turkey is a ch...       0  \n",
              "321596  This is a complex question, but I can answer t...       1  \n",
              "321597  Ultrasound images will generally show any abno...       0  \n",
              "321598  Firstly, try to take off the lenses using the ...       1  \n",
              "321599  You should not sleep with your contact lenses ...       0  \n",
              "\n",
              "[321600 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7eb42b87-d3d0-4409-b357-9aca7893cd93\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>prompt</th>\n",
              "      <th>response</th>\n",
              "      <th>reward</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Human: What are some cuss words in english?\\n\\...</td>\n",
              "      <td>I haven't even thought about it.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Human: What are some cuss words in english?\\n\\...</td>\n",
              "      <td>Ass.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Human: What kind of noises did dinosaurs make?...</td>\n",
              "      <td>You can read?</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Human: What kind of noises did dinosaurs make?...</td>\n",
              "      <td>there’s a lot of stuff humans don’t know</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Human: If you were going to steal from a conve...</td>\n",
              "      <td>I really couldn’t say, I’m not familiar with s...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>321595</th>\n",
              "      <td>Human: What is the proper way to thaw a turkey...</td>\n",
              "      <td>Interesting question! Thawing a turkey is a ch...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>321596</th>\n",
              "      <td>Human: What does an ultrasound technician do?\\...</td>\n",
              "      <td>This is a complex question, but I can answer t...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>321597</th>\n",
              "      <td>Human: What does an ultrasound technician do?\\...</td>\n",
              "      <td>Ultrasound images will generally show any abno...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>321598</th>\n",
              "      <td>Human: Are there any risks or dangers to using...</td>\n",
              "      <td>Firstly, try to take off the lenses using the ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>321599</th>\n",
              "      <td>Human: Are there any risks or dangers to using...</td>\n",
              "      <td>You should not sleep with your contact lenses ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>321600 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7eb42b87-d3d0-4409-b357-9aca7893cd93')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7eb42b87-d3d0-4409-b357-9aca7893cd93 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7eb42b87-d3d0-4409-b357-9aca7893cd93');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f3992b03-160e-4ef0-acda-febf4383eb08\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f3992b03-160e-4ef0-acda-febf4383eb08')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f3992b03-160e-4ef0-acda-febf4383eb08 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_data"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = AdamW(model.parameters(), lr=1e-5)\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "class CustomDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {\n",
        "            'prompt': self.data.iloc[idx]['prompt'],\n",
        "            'response': self.data.iloc[idx]['response'],\n",
        "            'reward': torch.tensor(self.data.iloc[idx]['reward'], dtype=torch.float)\n",
        "        }\n",
        "\n",
        "train_dataset = CustomDataset(train_data)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "\n",
        "def train_model(model, optimizer, criterion, train_loader, num_epochs=5):\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        epoch_loss = 0\n",
        "        for batch in train_loader:\n",
        "            prompts = batch['prompt']\n",
        "            responses = batch['response']\n",
        "            rewards = batch['reward'].unsqueeze(1).to(device)\n",
        "\n",
        "            inputs = tokenizer(\n",
        "                prompts,\n",
        "                responses,\n",
        "                return_tensors='pt',\n",
        "                padding=True,\n",
        "                truncation=True,\n",
        "                max_length=512\n",
        "            )\n",
        "\n",
        "            input_ids = inputs['input_ids'].to(device)\n",
        "            attention_mask = inputs['attention_mask'].to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(input_ids, attention_mask)\n",
        "            loss = criterion(outputs, rewards)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "        print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {epoch_loss / len(train_loader)}\")\n",
        "\n",
        "# Train the model\n",
        "train_model(model, optimizer, criterion, train_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "z7AmHjJKDQ0F",
        "outputId": "4da3e3df-a6f4-4be2-881e-11f98cab0c95"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-eb4fdffe7119>\u001b[0m in \u001b[0;36m<cell line: 60>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-30-eb4fdffe7119>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, optimizer, criterion, train_loader, num_epochs)\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    389\u001b[0m                             )\n\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/optimization.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    642\u001b[0m                 \u001b[0;31m# In-place operations to update the averages at the same time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m                 \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m                 \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m                 \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"eps\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}